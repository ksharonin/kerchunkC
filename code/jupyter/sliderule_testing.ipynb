{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic NB for Testing Values on Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metadata for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start JSON extraction from H5 file...\n",
      "JSON extraction complete\n"
     ]
    }
   ],
   "source": [
    "# gen ref for metadata inspection\n",
    "import kerchunk, fsspec, ujson\n",
    "from kerchunk import hdf\n",
    "\n",
    "def process(url, \n",
    "            outputfile, \n",
    "            storage_options_in={}, \n",
    "            storage_options_out={}):\n",
    "    \"\"\" generate h5 ref file using kerchunk known lib\n",
    "        https://github.com/fsspec/kerchunk/blob/37d75267cbf1c8d6ee1a9a69764cb661aa3f5e29/docs/source/advanced.rst#L30\n",
    "        class SingleHdf5ToZarr\n",
    "    \"\"\"\n",
    "    transformer = hdf.SingleHdf5ToZarr(url, **storage_options_in)\n",
    "    refs = transformer.translate()\n",
    "    with fsspec.open(outputfile, mode=\"wt\", **storage_options_out) as f:\n",
    "        ujson.dump(refs, f)\n",
    "\n",
    "URL = \"/Users/katrinasharonin/Downloads/OR_ABI-L2-FDCC-M3_G17_s20182390052191_e20182390054564_c20182390055159.nc\"\n",
    "# URL = \"/Users/katrinasharonin/Downloads/h5ex_d_gzip.h5\"\n",
    "OUTPUTFILE = \"/Users/katrinasharonin/Downloads/kerchunkC/jsons/sliderule_md_inspect.json\"\n",
    "\n",
    "print(\"Start JSON extraction from H5 file...\")\n",
    "process(URL, OUTPUTFILE)\n",
    "print(\"JSON extraction complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice and dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'long_name': 'ABI L2+ Fire-Hot Spot Characterization: Fire Radiative Power', 'standard_name': 'fire_radiative_power', 'valid_range': array([     0., 200000.], dtype=float32), 'units': 'MW', 'resolution': 'y: 0.000056 rad x: 0.000056 rad', 'grid_mapping': 'goes_imager_projection', 'cell_measures': 'area: Area', 'cell_methods': 'sunglint_angle: point (no pixel produced) local_zenith_angle: point (good quality pixel produced) solar_zenith_angle: point (good quality pixel produced) t: point', 'ancillary_variables': 'DQF'}\n",
      "fire_radiative_power\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr \n",
    "\n",
    "group_path = \"ancillary_data/calibrations/first_photon_bias/gt1l\"\n",
    "ds = xr.open_dataset(URL) #, group=group_path)\n",
    "\n",
    "varible = ds[\"Power\"]\n",
    "print(varible.attrs)\n",
    "fill = varible.attrs[\"standard_name\"]\n",
    "print(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "Area\n",
      "Temp\n",
      "Mask\n",
      "Power\n",
      "DQF\n",
      "t\n",
      "y\n",
      "x\n",
      "time_bounds\n",
      "goes_imager_projection\n",
      "y_image\n",
      "y_image_bounds\n",
      "x_image\n",
      "x_image_bounds\n",
      "nominal_satellite_subpoint_lat\n",
      "nominal_satellite_subpoint_lon\n",
      "nominal_satellite_height\n",
      "geospatial_lat_lon_extent\n",
      "sunglint_angle\n",
      "sunglint_angle_bounds\n",
      "local_zenith_angle\n",
      "local_zenith_angle_bounds\n",
      "solar_zenith_angle\n",
      "solar_zenith_angle_bounds\n",
      "total_number_of_pixels_with_fires_detected\n",
      "total_number_of_pixels_with_fire_temperature\n",
      "total_number_of_pixels_with_fire_area\n",
      "total_number_of_pixels_with_fire_radiative_power\n",
      "fire_temperature_outlier_pixel_count\n",
      "fire_area_outlier_pixel_count\n",
      "fire_radiative_power_outlier_pixel_count\n",
      "minimum_fire_temperature\n",
      "maximum_fire_temperature\n",
      "mean_fire_temperature\n",
      "standard_deviation_fire_temperature\n",
      "minimum_fire_area\n",
      "maximum_fire_area\n",
      "mean_fire_area\n",
      "standard_deviation_fire_area\n",
      "minimum_fire_radiative_power\n",
      "maximum_fire_radiative_power\n",
      "mean_fire_radiative_power\n",
      "standard_deviation_fire_radiative_power\n",
      "algorithm_dynamic_input_data_container\n",
      "processing_parm_version_container\n",
      "algorithm_product_version_container\n",
      "percent_uncorrectable_GRB_errors\n",
      "percent_uncorrectable_L0_errors\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables:\")\n",
    "for variable_name in ds.variables:\n",
    "    print(variable_name)\n",
    "    # for attr_name in ds[variable_name].attrs:\n",
    "       #  print(attr_name)\n",
    "    #     if attr_name == \"_FillValue\":\n",
    "    #         print(\"found\")\n",
    "    #         print(variable_name)\n",
    "    #         print(attr_name)\n",
    "\n",
    "\n",
    "print(\"_FillValue\" in ds.variables) # not a global one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Attributes\n",
      "long_name\n",
      "standard_name\n",
      "valid_range\n",
      "units\n",
      "resolution\n",
      "grid_mapping\n",
      "cell_measures\n",
      "cell_methods\n",
      "ancillary_variables\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'scale_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(attr_name))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_FillValue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTemp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscale_factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'scale_factor'"
     ]
    }
   ],
   "source": [
    "print(\"\\n Attributes\")\n",
    "for attr_name in ds[\"DQF\"].attrs:\n",
    "    print(attr_name)\n",
    "    # if \"_\" in attr_name:\n",
    "        # print(attr_name)\n",
    "print(type(ds.attrs))\n",
    "print(type(attr_name))\n",
    "\n",
    "print(\"_FillValue\" in ds.attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['naming_authority', 'Conventions', 'Metadata_Conventions', 'standard_name_vocabulary', 'institution', 'project', 'production_site', 'production_environment', 'spatial_resolution', 'orbital_slot', 'platform_ID', 'instrument_type', 'scene_id', 'instrument_ID', 'dataset_name', 'iso_series_metadata_id', 'title', 'summary', 'keywords', 'keywords_vocabulary', 'license', 'processing_level', 'date_created', 'cdm_data_type', 'time_coverage_start', 'time_coverage_end', 'timeline_id', 'production_data_source', 'id'])\n",
      "False\n",
      "Version attribute not found\n"
     ]
    }
   ],
   "source": [
    "# attr version\n",
    "print(ds.attrs.keys())\n",
    "print('version' in ds.attrs.keys())\n",
    "version_attribute = ds.attrs.get('version', 'Version attribute not found')\n",
    "print(version_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "# netcdf visit\n",
    "import netCDF4\n",
    "nc_file = netCDF4.Dataset(URL, 'r')\n",
    "format_version = nc_file.file_format\n",
    "print(format_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x89HDF'\n",
      "The NetCDF version of the file is: Unknown NetCDF Version\n"
     ]
    }
   ],
   "source": [
    "# try raw/IO request with offset \n",
    "\n",
    "def read_netcdf_version(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            \n",
    "            magic_bytes = file.read(4)\n",
    "            version = file.read(1)\n",
    "\n",
    "            \n",
    "            if magic_bytes == b'CDF\\x01' and version == b'\\x02':\n",
    "                print(magic_bytes)\n",
    "                return 'NetCDF-4'\n",
    "            elif magic_bytes == b'CDF\\x01' and version == b'\\x01':\n",
    "                print(magic_bytes)\n",
    "                return 'NetCDF Classic'\n",
    "            else:\n",
    "                print(magic_bytes)\n",
    "                return 'Unknown NetCDF Version'\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "file_path = URL\n",
    "version = read_netcdf_version(file_path)\n",
    "print(f\"The NetCDF version of the file is: {version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x89HDF\\r\\n\\x1a\\n\\x02\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "b'\\x89HDF\\r\\n\\x1a\\n\\x00\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x04\\x00\\x10\\x00'\n"
     ]
    }
   ],
   "source": [
    "file_path = URL\n",
    "alt_path = \"/Users/katrinasharonin/Downloads/h5ex_d_gzip.h5\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        print(file.read(20))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    with open(alt_path, 'rb') as file:\n",
    "        print(file.read(20))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerchunkc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
