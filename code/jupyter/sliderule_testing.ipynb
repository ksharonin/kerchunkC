{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic NB for Testing Values on Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metadata for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start JSON extraction from H5 file...\n",
      "JSON extraction complete\n"
     ]
    }
   ],
   "source": [
    "# gen ref for metadata inspection\n",
    "import kerchunk, fsspec, ujson\n",
    "from kerchunk import hdf\n",
    "\n",
    "def process(url, \n",
    "            outputfile, \n",
    "            storage_options_in={}, \n",
    "            storage_options_out={}):\n",
    "    \"\"\" generate h5 ref file using kerchunk known lib\n",
    "        https://github.com/fsspec/kerchunk/blob/37d75267cbf1c8d6ee1a9a69764cb661aa3f5e29/docs/source/advanced.rst#L30\n",
    "        class SingleHdf5ToZarr\n",
    "    \"\"\"\n",
    "    transformer = hdf.SingleHdf5ToZarr(url, **storage_options_in)\n",
    "    refs = transformer.translate()\n",
    "    with fsspec.open(outputfile, mode=\"wt\", **storage_options_out) as f:\n",
    "        ujson.dump(refs, f)\n",
    "\n",
    "URL = \"/Users/katrinasharonin/Downloads/OR_ABI-L2-FDCC-M3_G17_s20182390052191_e20182390054564_c20182390055159.nc\"\n",
    "URL = \"/Users/katrinasharonin/Downloads/h5ex_d_gzip.h5\"\n",
    "OUTPUTFILE = \"/Users/katrinasharonin/Downloads/kerchunkC/jsons/sliderule_md_inspect.json\"\n",
    "\n",
    "print(\"Start JSON extraction from H5 file...\")\n",
    "process(URL, OUTPUTFILE)\n",
    "print(\"JSON extraction complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice and dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "\n",
    "group_path = \"ancillary_data/calibrations/first_photon_bias/gt1l\"\n",
    "ds = xr.open_dataset(URL) #, group=group_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables:\")\n",
    "for variable_name in ds.variables:\n",
    "    # print(variable_name)\n",
    "    for attr_name in ds[variable_name].attrs:\n",
    "        if attr_name == \"_FillValue\":\n",
    "            print(\"found\")\n",
    "            print(variable_name)\n",
    "            print(attr_name)\n",
    "\n",
    "\n",
    "print(\"_FillValue\" in ds.variables) # not a global one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Attributes\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Attributes\")\n",
    "for attr_name in ds.attrs:\n",
    "    print(attr_name)\n",
    "    # if \"_\" in attr_name:\n",
    "        # print(attr_name)\n",
    "print(type(ds.attrs))\n",
    "print(type(attr_name))\n",
    "\n",
    "print(\"_FillValue\" in ds.attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['naming_authority', 'Conventions', 'Metadata_Conventions', 'standard_name_vocabulary', 'institution', 'project', 'production_site', 'production_environment', 'spatial_resolution', 'orbital_slot', 'platform_ID', 'instrument_type', 'scene_id', 'instrument_ID', 'dataset_name', 'iso_series_metadata_id', 'title', 'summary', 'keywords', 'keywords_vocabulary', 'license', 'processing_level', 'date_created', 'cdm_data_type', 'time_coverage_start', 'time_coverage_end', 'timeline_id', 'production_data_source', 'id'])\n",
      "False\n",
      "Version attribute not found\n"
     ]
    }
   ],
   "source": [
    "# attr version\n",
    "print(ds.attrs.keys())\n",
    "print('version' in ds.attrs.keys())\n",
    "version_attribute = ds.attrs.get('version', 'Version attribute not found')\n",
    "print(version_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "# netcdf visit\n",
    "import netCDF4\n",
    "nc_file = netCDF4.Dataset(URL, 'r')\n",
    "format_version = nc_file.file_format\n",
    "print(format_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x89HDF'\n",
      "The NetCDF version of the file is: Unknown NetCDF Version\n"
     ]
    }
   ],
   "source": [
    "# try raw/IO request with offset \n",
    "\n",
    "def read_netcdf_version(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            \n",
    "            magic_bytes = file.read(4)\n",
    "            version = file.read(1)\n",
    "\n",
    "            \n",
    "            if magic_bytes == b'CDF\\x01' and version == b'\\x02':\n",
    "                print(magic_bytes)\n",
    "                return 'NetCDF-4'\n",
    "            elif magic_bytes == b'CDF\\x01' and version == b'\\x01':\n",
    "                print(magic_bytes)\n",
    "                return 'NetCDF Classic'\n",
    "            else:\n",
    "                print(magic_bytes)\n",
    "                return 'Unknown NetCDF Version'\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "file_path = URL\n",
    "version = read_netcdf_version(file_path)\n",
    "print(f\"The NetCDF version of the file is: {version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x89HDF\\r\\n\\x1a\\n\\x02\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "b'\\x89HDF\\r\\n\\x1a\\n\\x00\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x04\\x00\\x10\\x00'\n"
     ]
    }
   ],
   "source": [
    "file_path = URL\n",
    "alt_path = \"/Users/katrinasharonin/Downloads/h5ex_d_gzip.h5\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        print(file.read(20))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    with open(alt_path, 'rb') as file:\n",
    "        print(file.read(20))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerchunkc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
